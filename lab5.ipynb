{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9f5995-d636-4949-9ee3-bf820aae0b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbc7a67-f091-483c-a304-06bda3083d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Predictions: [2.3583618  2.26897099 2.35871357 2.3729983  2.37665259]\n",
      "Test Predictions: [2.38788876 2.42262009 2.40487585 2.3569433  2.36478988]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def train_linear_regression_model(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Use one feature\n",
    "X = df[[\"embedding_0\"]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = train_linear_regression_model(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Output results\n",
    "print(\"Train Predictions:\", y_train_pred[:5])\n",
    "print(\"Test Predictions:\", y_test_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ca22417-9dd3-4f1d-812a-4edaa65698a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.519312349012836\n",
      "RMSE: 0.7206332971857712\n",
      "MAPE: 0.36429633067533557\n",
      "R² Score: -0.002986062652017507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Use one embedding feature (embedding_0)\n",
    "X = df[[\"embedding_0\"]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R² Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f79c9b9-7278-4815-8905-34736ddeb347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions on test set: [2.52006721 2.67136752 2.43934959 2.84266422 2.9987155 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Select all embedding columns\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"First 5 predictions on test set:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "584ac2be-6c7f-4dc6-8d80-28960a93a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Binary classification: Ensure labels are 0 or 1\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values  # Ensure integer labels\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Predictions:\", y_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51d16263-741b-4972-a34a-4cbebdfbaa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.02      0.04        92\n",
      "           2       0.45      0.33      0.38       213\n",
      "           3       0.59      0.83      0.69       358\n",
      "\n",
      "    accuracy                           0.56       663\n",
      "   macro avg       0.57      0.39      0.37       663\n",
      "weighted avg       0.55      0.56      0.50       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Features and target\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91f745d-8e69-4ac4-902f-4035f565964c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA output shape: (3311, 2)\n",
      "First 5 PCA components:\n",
      " [[-5.32297459 -2.46619606]\n",
      " [-5.09184631 -4.46762428]\n",
      " [ 0.95173992 -8.10319771]\n",
      " [12.05146418  1.09632425]\n",
      " [-3.91290969  3.28138902]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"PCA output shape:\", X_pca.shape)\n",
    "print(\"First 5 PCA components:\\n\", X_pca[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "288b555a-e65d-403e-87db-014e0bec7bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        92\n",
      "           2       0.40      0.01      0.02       213\n",
      "           3       0.54      0.99      0.70       358\n",
      "\n",
      "    accuracy                           0.54       663\n",
      "   macro avg       0.31      0.33      0.24       663\n",
      "weighted avg       0.42      0.54      0.38       663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9236a9-94e2-475e-b0bf-8ba1470adc05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
